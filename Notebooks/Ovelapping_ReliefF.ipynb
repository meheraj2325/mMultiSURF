{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ovelapping_ReliefF.ipynb","provenance":[{"file_id":"1RHS6ELJYsVTxnbq2lh-pQXUWLlZmd_Zn","timestamp":1609067966009}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"code","metadata":{"id":"a6utNr_2Ae1g"},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.neighbors import NearestNeighbors\n","import pandas as pd\n","import math\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHaRYqCnykZz"},"source":["def check_numeric(X):\n","  newX = np.array(X).reshape(-1)\n","  return all(not isinstance(n, str) for n in newX)\n","\n","# X=np.array([[6,7,8],[3,0,5]])\n","# print(check_numeric(X))\n","# print(X)\n","# print(check_numeric([1,2,3]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n4lcmIQvsn6Q"},"source":["def error_return(p):\n","  ranked = np.arange(p, dtype=int) \n","  weight = np.empty((1,p))\n","  weight = np.squeeze(weight) \n","  weight[:] = np.nan\n","  return ranked, weight"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MDCPZoSWJzf9"},"source":["\n","### Preprocessing data and call feature selection algorithm"]},{"cell_type":"code","metadata":{"id":"FToEQpI3J5gK"},"source":["def Ovelapping_ReliefF_configure(X,Y,K, **kwargs):\n","  X = np.array(X)\n","  Y = np.array(Y)\n","  prior, numUpdates, categoricalX, kernelWidth = kwargs['prior'], kwargs['numUpdates'], kwargs['categoricalX'], kwargs['kernelWidth']\n","\n","  # if not check_numeric(X):\n","  #   print('X does not contain numeric data')\n","  #   p = X.shape[1] # no of attributes\n","  #   return error_return(p) \n","\n","  # Check if the input sizes are consistent\n","  if Y.shape[0] != X.shape[0]:\n","    print('number of instances and output labels doesnot match')\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","  \n","  # converting classes as 0 to #classes\n","  [Y, grp] = pd.factorize(Y)\n","\n","  # grpToInd contains class to index mapping, grpToInd[className]= ind\n","  grpToInd={}\n","  for ind, g in enumerate(grp):\n","    grpToInd[g]= ind\n","\n","  # removing incomplete instances\n","  # df_XY = pd.DataFrame(X)\n","  # df_XY['Y'] = Y\n","  # df_XY = df_XY.dropna()\n","  # X, Y = np.array(df_XY.iloc[:, 0:-1]), np.array(df_XY.iloc[:, -1])\n","  \n","  Ngrp = len(grp)\n","  N = X.shape[0]\n","  C = np.zeros((N,Ngrp))\n","  C[np.arange(N), Y] = True\n","  \n","  # Get class probs\n","  if not prior or prior == 'empirical':\n","    classProb = C.sum(0)\n","  elif prior == 'uniform':\n","    classProb = np.ones((1, Ngrp))\n","  elif isinstance(prior, dict):\n","    classProb = np.zeros((1,Ngrp))\n","    # if prior is a dictionary of class and prior prob\n","    if not len(prior):\n","      print('prior dictionrary is empty')\n","      p = X.shape[1] # no of attributes\n","      return error_return(p)\n","    for g, prob in prior.items():\n","      classProb[grpToInd[g]]=prob\n","  elif check_numeric(prior):\n","    if len(prior)!= Ngrp or any(p <0 for p in prior) or not all(isinstance(p, float) for p in prior) or all(p == 0 for p in prior) :\n","      print('prior doesnot fulfil all conditions')\n","      p = X.shape[1] # no of attributes\n","      return error_return(p)\n","    classProb = prior\n","  else:\n","    print('prior is invalid')\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","  \n","  #  Normalize class probs\n","  classProb = classProb/classProb.sum()\n","  classProb = np.squeeze(classProb) \n","  #  If there are classes with zero probs, remove them\n","  zeroProb = classProb != 0\n","  \n","  t = [ not classProb[y]==0 for y in Y] # contains array of size [Ngrp,1] with values [True, True, False ...]\n","  X = X[t]\n","  Y = Y[t]\n","  C = C[t]\n","  C = C[:,zeroProb]\n","  classProb = classProb[zeroProb]\n","\n","  #  Do we have enough observations?\n","  if len(Y)<2:\n","    print('not enough instances')\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","\n","  if not check_numeric([K]) or K<0:\n","    print('invalid value of K')\n","    p = X.shape[1] # no of attributes\n","    return error_return(property)\n","  K= math.ceil(K)\n","\n","  # Check number of updates\n","  if (not numUpdates=='all') and (not check_numeric([numUpdates]) or numUpdates<=0):\n","    print('numUpdates is invalid')\n","  elif (not numUpdates) or numUpdates=='all':\n","    numUpdates = X.shape[0]\n","  else:\n","    numUpdates = math.ceil(numUpdates)\n","    \n","  # Check the type of categoricalX\n","  if not categoricalX or (categoricalX != 'on' and categoricalX != 'off'):\n","    print('categoricalX is invalid')\n","  categoricalX = (categoricalX == 'on')   \n","\n","  # Find max and min for every predictor\n","  p = X.shape[1] # no of attributes\n","  Xmax = X.max(0)\n","  Xmin = X.min(0) \n","  Xdiff = Xmax - Xmin\n","  Xmean = np.mean(X, axis=0) \n","\n","  # Exclude single-valued attributes\n","  isDiffValue = Xdiff >= 1e-9  # boolean array of size #attributes [1,0,0,0]\n","  if not any(isDiffValue):\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","  \n","  X = X[:, isDiffValue ] \n","  Xmax = Xmax[isDiffValue] \n","  Xmin = Xmin[isDiffValue]\n","  Xdiff = Xdiff[isDiffValue] \n","  Xmean = Xmean[isDiffValue]\n","  rejected = [ i for i in range(len(isDiffValue)) if not isDiffValue[i]]  # indices of the deleted attributes (values range from 1 to p)\n","  accepted = [ i for i in range(len(isDiffValue)) if isDiffValue[i]]  # indices of remaining attributes (values range from 1 to p)\n","\n","  # Scale and center the attributes\n","  if not categoricalX:\n","    X = (X - Xmin) / Xdiff \n","\n","  # The #updates cannot be more than the #observations\n","  numUpdates = min(numUpdates, X.shape[0])\n","\n","  # Call Ovelapping_ReliefF. By default all weights are set to NaN.\n","  weight = np.empty(p) \n","  weight[:] = np.nan\n","\n","  weight[accepted] = Ovelapping_ReliefF(X,C,classProb,numUpdates,K,categoricalX, kernelWidth) \n","\n","  # Assign ranks to attributes\n","  sorted = np.argsort(-weight[accepted])\n","  accepted = np.array(accepted)\n","  ranked = accepted[sorted]\n","  ranked = np.append(ranked, rejected)\n","  ranked = ranked.astype(int)\n","\n","  return ranked, weight "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6a1zuATsNfV1"},"source":["# Ovelapping_ReliefF algorithm function"]},{"cell_type":"code","metadata":{"id":"1qwWjfJzAe2u"},"source":["def Ovelapping_ReliefF(scaledX,C,classProb,numUpdates,K,categoricalX, kernelWidth):\n","  \n","  # Ovelapping_ReliefF for classification\n","  numInstances,numAttr = scaledX.shape \n","  attrWeights = np.zeros(numAttr) \n","  # C is boolean 2D matrix of size (N, Ngrp) i.e. (Number of instances vs Number of classes)\n","  numClasses = C.shape[1]   # Ngrp\n","\n","  # Choose the random instances\n","  np.random.seed(123)\n","  rndIdx = np.random.choice(numInstances, numUpdates, replace=False)   # random indices of m instances from total of n instances\n","  idxVec = np.arange(numInstances)   # [0 .. N-1]\n","\n","   # Make searcher objects, one object per class. \n","  instIdxPerClass = {}  \n","  for c in range(numClasses):\n","    c_C = C[:,c]\n","    instIdxPerClass[c] = np.array([i for i in range(len(c_C)) if c_C[i]], dtype=int)   # instances of class c\n","  \n","  # selecting distance function\n","  distFunc = 'manhattan'\n","  if categoricalX:\n","    distFunc = 'hamming'\n","  else: \n","    distFunc = 'manhattan'\n","  \n","   # Outer loop, for updating attribute weights iteratively\n","  for i in range(numUpdates):\n","    targetIdx = rndIdx[i]\n","    \n","    # Choose the correct random observation\n","    targetInst = scaledX[targetIdx,:]\n","\n","    # Find the class for this observation\n","    targetC = C[targetIdx, :]\n","    thisC = np.array([i for i in range(len(targetC)) if targetC[i]]).item() # taking the class of target instance\n","    \n","    # Find the k-nearest hits \n","    sameClassIdx = instIdxPerClass[thisC] \n","    \n","    # we may not always find numNeighbor Hits\n","    lenHits = min(len(sameClassIdx)-1,K) \n","\n","    # find nearest hits\n","    # It is not guaranteed that the first hit is the same as targetIdx. Since\n","    # they have the same class, it does not matter. If we add observation\n","    # weights in the future, we will need here something similar to what we\n","    # do in ReliefReg.\n","    # print('HitFit : ', scaledX[sameClassIdx])\n","    Hits = [] \n","    if lenHits>0:\n","      nearestNeighborHits = NearestNeighbors(n_neighbors=lenHits+1, algorithm='auto', metric= distFunc).fit(scaledX[sameClassIdx])\n","      idxH = nearestNeighborHits.kneighbors([targetInst], lenHits+1, return_distance=False)\n","      idxH = np.squeeze(idxH)\n","      Hits = sameClassIdx[idxH[1:]] \n","\n","    # Process misses\n","    missClass = [i for i in range(len(targetC)) if not targetC[i]]\n","    Misses = {} \n","    \n","    if len(missClass):  # Make sure there are misses!\n","      # Find the k-nearest misses Misses(C,:) for each class C ~= class(targetInst)\n","      # Misses will be of a dictionary\n","      \n","      for mi in range(len(missClass)):\n","        \n","        # find all observations of this miss class\n","        missClassIdx = instIdxPerClass[missClass[mi]]\n","        \n","        # we may not always find K misses\n","        lenMiss = min(len(missClassIdx),K) \n","        \n","        # print('Missfit :', scaledX[missClassIdx])\n","\n","        # find nearest misses\n","        if lenMiss>0:\n","          nearestNeighborMiss = NearestNeighbors(n_neighbors=lenMiss, algorithm='auto', metric= distFunc).fit(scaledX[missClassIdx])\n","          idxM = nearestNeighborMiss.kneighbors([targetInst], lenMiss, return_distance=False)\n","          idxM = np.squeeze(idxM)\n","          Misses[missClass[mi]] = np.array([], dtype='int')\n","          Misses[missClass[mi]] = np.append(Misses[missClass[mi]], missClassIdx[idxM])\n","      \n","        # Misses contains obs indices for miss classes, sorted by dist\n","            \n","    #***************** ATTRIBUTE UPDATE *****************************\n","    # Inner loop to update weights for each attribute:\n","\n","    # print('targetID :',targetIdx)\n","    # print(\"target :\",targetInst)\n","    # print('HitId :', Hits)\n","    # print(\"Hit :\", X[Hits])\n","    # print('MissId :', Misses)\n","       \n","    for j in range(numAttr):\n","      dH = diffH(j, scaledX, targetIdx, Hits, Misses, categoricalX, kernelWidth)/numUpdates\n","      # print('dH', dH) \n","      dM = diffM(j, scaledX, targetIdx, Hits, Misses, categoricalX, classProb, kernelWidth)/numUpdates\n","      # print('dM', dM)\n","      attrWeights[j] = attrWeights[j] - dH + dM \n","      attrWeights[j] = attrWeights[j]\n","\n","      \n","      #****************************************************************\n","    \n","    # print('attrWeights : ', attrWeights)\n","  \n","  return attrWeights    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLkuPu0v2tRo"},"source":["def cityblock(thisX, X):\n","  d = abs(X - thisX) \n","  return d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-2iwGin2tdA"},"source":["def hamming(thisX, X):\n","  d = (X != thisX).astype(int) \n","  return d\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Forqe9GXI_h"},"source":["def kernel_func(d, kernelWidth):\n","  return np.exp(-d/kernelWidth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w40aIoG-Ae28"},"source":["#--------------------------------------------------------------------------\n","# DIFFH (for Overlapping_MultiSurfClass): Function to calculate difference measure\n","# for an attribute between the selected instance and its hits\n","\n","def diffH(a, X, targetIdx, Hits, Misses, categoricalX, kernelWidth):\n","\n","  # print(a, targetIdx, Hits, categoricalX)\n","\n","  missesInd = np.array([], dtype = 'int')\n","  for indices in Misses.values():\n","    missesInd =  np.append(missesInd, indices)\n","\n","  missesInd = missesInd.astype(int)\n","\n","  # If no hits, return zero by default\n","  if not len(Hits):\n","      return 0\n","\n","  # Calculate weighted sum of distances\n","  distFunc = hamming if categoricalX else cityblock \n","\n","  distMeas = 0\n","  totalPNotInOverlapping = 0\n","  # for hit in Hits:\n","  #   otherHits = Hits[Hits != hit]\n","  #   totalNeighbours = np.append(otherHits, missesInd)\n","  #   # pNotInOverlapping is the probability of a neighbour not being in an overlapping area\n","  #   pNotInOverlapping = np.sum(kernel_func(distFunc(X[hit, a], X[otherHits,a]), kernelWidth)) / np.sum(kernel_func(distFunc(X[hit, a], X[totalNeighbours,a]), kernelWidth))\n","  #   distMeas += pNotInOverlapping * distFunc(X[targetIdx, a], X[hit,a])\n","  #   totalPNotInOverlapping += pNotInOverlapping\n","\n","  for hit in Hits:\n","    otherHits = np.append(Hits[Hits != hit], targetIdx)\n","    totalNeighbours = np.append(otherHits, missesInd)\n","    # pNotInOverlapping is the probability of a neighbour not being in an overlapping area\n","    pNotInOverlapping = 1\n","    if len(missesInd)>0:\n","      pNotInOverlapping = 1 - np.sum(kernel_func(distFunc(X[hit, a], X[missesInd,a]), kernelWidth)) / np.sum(kernel_func(distFunc(X[hit, a], X[totalNeighbours,a]), kernelWidth))\n","    distMeas += pNotInOverlapping * distFunc(X[targetIdx, a], X[hit,a])\n","    totalPNotInOverlapping += pNotInOverlapping\n","\n","  # print('For attribute ',a,' Hit distmeas : ', distMeas/len(Hits))\n","\n","  if totalPNotInOverlapping>0:\n","    return distMeas/totalPNotInOverlapping\n","  else:\n","   return distMeas\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Rb0WZu42j7T"},"source":["#--------------------------------------------------------------------------\n","# DIFFM (for Overlapping_MultiSurfClass) : Function to calculate difference measure\n","# for an attribute between the selected instance and its misses\n","def diffM(a, X, targetIdx, Hits, Misses, categoricalX, classProb, kernelWidth):\n","  \n","  # print(a, targetIdx, Misses, categoricalX)\n","\n","  missesInd = np.array([], dtype='int')\n","  for indices in Misses.values():\n","    missesInd =  np.append(missesInd, indices)\n","\n","  missesInd = missesInd.astype(int)\n","\n","  # print('missesInd = ', missesInd)\n","\n","  # If no hits, return zero by default\n","  if not len(missesInd):\n","      return 0.0\n","\n","  # Calculate weighted sum of distances\n","  distFunc = hamming if categoricalX else cityblock \n","\n","  distMeas = 0.0\n","  # for missIdx in Misses.values():\n","  #   for miss in missIdx:\n","  #     otherMisses = missIdx[missIdx != miss]\n","  #     totalNeighbours = np.append(missesInd[missesInd!=miss], Hits)\n","  #     # pNotInOverlapping is the probability of a neighbour not being in an overlapping area\n","  #     pNotInOverlapping = np.sum(kernel_func(distFunc(X[miss, a], X[otherMisses,a]), kernelWidth)) / np.sum(kernel_func(distFunc(X[miss, a], X[totalNeighbours,a]), kernelWidth))\n","  #     distMeas += pNotInOverlapping * distFunc(X[targetIdx, a], X[miss,a])\n","  #     totalPNotInOverlapping += pNotInOverlapping\n","\n","  totalMisses = 0.0\n","  for missIdx in Misses.values():\n","    totalMisses += len(missIdx)\n","\n","  totProb = 0.0\n","\n","  Hits = np.append(Hits, targetIdx)\n","  for cls, missIdx in Misses.items():\n","    missIdx = missIdx.astype(int)\n","    totalPNotInOverlappingPerClass = 0.0\n","    distMeasPerClass = 0.0\n","    totProb += classProb[cls]\n","    for miss in missIdx:\n","      otherMisses = missIdx[missIdx != miss]\n","      totalNeighbours = np.append(missesInd[missesInd!=miss], Hits).astype(int)\n","      otherClassInd = np.array([ind for ind in totalNeighbours if ind not in otherMisses], dtype= 'int')\n","      # if not otherClassInd.shape[0]:\n","      #   print('otherClassInd = ',otherClassInd)\n","      # pNotInOverlapping is the probability of a neighbour not being in an overlapping area\n","      pNotInOverlapping = 1\n","      if len(otherClassInd)>0:\n","        pNotInOverlapping = 1 - np.sum(kernel_func(distFunc(X[miss, a], X[otherClassInd,a]), kernelWidth)) / np.sum(kernel_func(distFunc(X[miss, a], X[totalNeighbours,a]), kernelWidth))\n","      # if pNotInOverlapping==0:\n","      #   print('pNotInOverlapping = ',pNotInOverlapping)      \n","      distMeasPerClass += pNotInOverlapping * distFunc(X[targetIdx, a], X[miss,a])\n","      totalPNotInOverlappingPerClass += pNotInOverlapping\n","    \n","    if totalPNotInOverlappingPerClass > 0.0:\n","      distMeas += (distMeasPerClass * classProb[cls])/totalPNotInOverlappingPerClass\n","    else:\n","      distMeas += (distMeasPerClass * classProb[cls])\n","\n","  if totProb>0:\n","    return distMeas/totProb\n","  else:\n","   return distMeas"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aOX0asWFteMH"},"source":["# from sklearn.datasets import load_iris, load_digits, load_wine\n","# X, Y = load_digits(return_X_y= True)\n","# print('dataset: digits')\n","# ranked, weight = Ovelapping_ReliefF_configure(X,Y,K=10,prior='uniform', numUpdates='all', categoricalX='off')\n","# print(ranked, weight)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"24fjwbzxuzBa"},"source":["# X = np.array([[0,0,0,0,1,0,0],\n","#               [0,1,0,1,0,1,0],\n","#               [1,0,0,0,1,1,0],\n","#               [0,0,0,1,0,0,0],\n","#               [1,1,0,0,0,0,0],\n","#               [0,1,0,0,1,0,0],\n","#               [0,0,0,0,0,1,0],\n","#               [1,0,0,1,0,0,0],\n","#               [1,0,1,0,0,0,1],\n","#               [1,1,0,0,1,0,1],\n","#               [0,0,0,0,0,0,1],\n","#               [1,0,1,1,1,1,1],\n","#               [1,0,0,0,0,0,0],\n","#               [1,0,0,1,0,1,1],\n","#               [0,1,1,0,0,0,0],\n","#               [0,0,1,1,0,0,1],\n","#               [1,1,0,1,0,0,0],\n","#               [1,0,1,0,1,0,1],\n","#               [0,1,1,1,0,0,1],\n","#               [1,1,1,1,1,1,1]])\n","\n","# Y = np.array([0,1,1,0,0,1,0,1,1,0,0,1,1,1,1,0,0,1,1,0])\n","\n","# Ovelapping_ReliefF_configure(X,Y,K=3,prior='uniform', numUpdates='all', categoricalX='on')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQe2rjPuiyP5"},"source":["# X = np.array([[1,0,1],\n","#               [1,0,0],\n","#               [0,1,1],\n","#               [0,1,0],\n","#               [0,0,1],\n","#               [0,0,0],\n","#               [1,1,1],\n","#               [1,1,0]])\n","\n","# Y = np.array([1,1,1,1,0,0,0,0])\n","# ranked, weight= Ovelapping_ReliefF_configure(X,Y,K=1,prior='uniform', numUpdates='all', categoricalX='on')\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQgt2FhDQL5a"},"source":["# def permute(x):\n","#   if len(x) == 7:\n","#     global X\n","#     global Y\n","#     Y.append((x[0] ^ x[1]))\n","#     X.append(x)\n","#     return\n","#   x = np.append(x,0)\n","#   permute(x)\n","#   x = x[0:-1]\n","#   x = np.append(x,1)\n","#   permute(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLcbYBwbXmAd"},"source":["# X = []\n","# Y = []\n","# x = np.array([], dtype=int)\n","# permute(x)\n","# X = np.array(X)\n","# Y = np.array(Y)\n","# ranked, weight=Ovelapping_ReliefF_configure(X,Y,K=10,prior='uniform', numUpdates=len(Y)/2, categoricalX='on')\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6g9wkOs_fTTi"},"source":["# # test classification dataset\n","# from sklearn.datasets import make_classification\n","# # define dataset\n","# X, Y = make_classification(n_samples=100, n_features=15, n_informative=10, n_redundant=0,shuffle=False, random_state=1)\n","# # summarize the dataset\n","# print(X.shape, Y.shape)\n","# ranked, weight= Ovelapping_ReliefF_configure(X,Y,K=10,prior='uniform', numUpdates='all', categoricalX='off', kernelWidth=3)\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"x-KtNUhxe5KZ"},"source":[""],"execution_count":null,"outputs":[]}]}