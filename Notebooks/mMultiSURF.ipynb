{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"Modified_Overlapping_MultiSurf.ipynb","provenance":[{"file_id":"1u1eiKe-QhPi-9QWNnF0_2RcfKOaY1OR3","timestamp":1608838081529}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"a6utNr_2Ae1g"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.spatial.distance import pdist, squareform\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import pairwise_distances as pair_dist\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.neighbors import NearestNeighbors\n","import pandas as pd\n","import math\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHaRYqCnykZz"},"source":["def check_numeric(X):\n","  newX = np.array(X).reshape(-1)\n","  return all(not isinstance(n, str) for n in newX)\n","\n","# X=np.array([[6,7,8],[3,0,5]])\n","# print(check_numeric(X))\n","# print(X)\n","# print(check_numeric([1,2,3]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n4lcmIQvsn6Q"},"source":["def error_return(p):\n","  ranked = np.arange(p, dtype=int) \n","  weight = np.empty((1,p))\n","  weight = np.squeeze(weight) \n","  weight[:] = np.nan\n","  return ranked, weight"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MDCPZoSWJzf9"},"source":["\n","### Preprocessing data and call feature selection algorithm"]},{"cell_type":"code","metadata":{"id":"FToEQpI3J5gK"},"source":["def Modified_Overlapping_MultiSurf_configure(X,Y, **kwargs):\n","  X = np.array(X)\n","  Y = np.array(Y)\n","  prior, numUpdates, categoricalX, kernelWidth = kwargs['prior'], kwargs['numUpdates'], kwargs['categoricalX'], kwargs['kernelWidth']\n","\n","  # if not check_numeric(X):\n","  #   print('X does not contain numeric data')\n","  #   p = X.shape[1] # no of attributes\n","  #   return error_return(p) \n","\n","  # Check if the input sizes are consistent\n","  if Y.shape[0] != X.shape[0]:\n","    print('number of instances and output labels doesnot match')\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","  \n","  # converting classes as 0 to #classes\n","  [Y, grp] = pd.factorize(Y)\n","\n","  # grpToInd contains class to index mapping, grpToInd[className]= ind\n","  grpToInd={}\n","  for ind, g in enumerate(grp):\n","    grpToInd[g]= ind\n","\n","  # # removing incomplete instances\n","  # df_XY = pd.DataFrame(X)\n","  # df_XY['Y'] = Y\n","  # df_XY = df_XY.dropna()\n","  # X, Y = np.array(df_XY.iloc[:, 0:-1]), np.array(df_XY.iloc[:, -1])\n","  \n","  Ngrp = len(grp)\n","  N = X.shape[0]\n","  C = np.zeros((N,Ngrp))\n","  C[np.arange(N), Y] = True\n","  \n","  # Get class probs\n","  if not prior or prior == 'empirical':\n","    classProb = C.sum(0)\n","  elif prior == 'uniform':\n","    classProb = np.ones((1, Ngrp))\n","  elif isinstance(prior, dict):\n","    classProb = np.zeros((1,Ngrp))\n","    # if prior is a dictionary of class and prior prob\n","    if not len(prior):\n","      print('prior dictionrary is empty')\n","      p = X.shape[1] # no of attributes\n","      return error_return(p)\n","    for g, prob in prior.items():\n","      classProb[grpToInd[g]]=prob\n","  elif check_numeric(prior):\n","    if len(prior)!= Ngrp or any(p <0 for p in prior) or not all(isinstance(p, float) for p in prior) or all(p == 0 for p in prior) :\n","      print('prior doesnot fulfil all conditions')\n","      p = X.shape[1] # no of attributes\n","      return error_return(p)\n","    classProb = prior\n","  else:\n","    print('prior is invalid')\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","  \n","  #  Normalize class probs\n","  classProb = classProb/classProb.sum()\n","  classProb = np.squeeze(classProb) \n","  #  If there are classes with zero probs, remove them\n","  zeroProb = classProb != 0\n","  \n","  t = [ not classProb[y]==0 for y in Y] # contains array of size [Ngrp,1] with values [True, True, False ...]\n","  X = X[t]\n","  Y = Y[t]\n","  C = C[t]\n","  C = C[:,zeroProb]\n","  classProb = classProb[zeroProb]\n","\n","  #  Do we have enough observations?\n","  if len(Y)<2:\n","    print('not enough instances')\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","\n","  # if not check_numeric([K]) or K<0:\n","  #   print('invalid value of K')\n","  #   p = X.shape[1] # no of attributes\n","  #   return error_return(property)\n","  # K= math.ceil(K)\n","\n","  # Check number of updates\n","  if (not numUpdates=='all') and (not check_numeric([numUpdates]) or numUpdates<=0):\n","    print('numUpdates is invalid')\n","  elif (not numUpdates) or numUpdates=='all':\n","    numUpdates = X.shape[0]\n","  else:\n","    numUpdates = math.ceil(numUpdates)\n","    \n","  # Check the type of categoricalX\n","  if not categoricalX or (categoricalX != 'on' and categoricalX != 'off'):\n","      print('categoricalX is invalid')\n","  categoricalX = (categoricalX == 'on')   \n","\n","  # Find max and min for every predictor\n","  p = X.shape[1] # no of attributes\n","  Xmax = X.max(0)\n","  Xmin = X.min(0) \n","  Xdiff = Xmax - Xmin\n","  Xmean = np.mean(X, axis=0) \n","\n","  # Exclude single-valued attributes\n","  isDiffValue = Xdiff >= 1e-9  # boolean array of size #attributes [1,0,0,0]\n","  if not any(isDiffValue):\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","  \n","  X = X[:, isDiffValue ]\n","  Xmax = Xmax[isDiffValue ] \n","  Xmin = Xmin[isDiffValue ]  \n","  Xdiff = Xdiff[isDiffValue] \n","  Xmean = Xmean[isDiffValue]\n","  rejected = [ i for i in range(len(isDiffValue)) if not isDiffValue[i]]  # indices of the deleted attributes (values range from 1 to p)\n","  accepted = [ i for i in range(len(isDiffValue)) if isDiffValue[i]]  # indices of remaining attributes (values range from 1 to p)\n","\n","  # Scale and center the attributes\n","  if not categoricalX:\n","      X = (X - Xmin) / Xdiff \n","\n","  # The #updates cannot be more than the #observations\n","  numUpdates = min(numUpdates, X.shape[0])\n","\n","  # Call MultiSurf. By default all weights are set to NaN.\n","  weight = np.empty(p) \n","  weight[:] = np.nan\n","\n","  weight[accepted] = Modified_Overlapping_MultiSurf(X, Y, C,classProb,numUpdates,categoricalX, kernelWidth) \n","\n","  # Assign ranks to attributes\n","  sorted = np.argsort(-weight[accepted])\n","  accepted = np.array(accepted)\n","  ranked = accepted[sorted]\n","  ranked = np.append(ranked, rejected)\n","  ranked = ranked.astype(int)\n","\n","  return ranked, weight \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6a1zuATsNfV1"},"source":["# Overlapping_MultiSurf algorithm function"]},{"cell_type":"code","metadata":{"id":"1qwWjfJzAe2u"},"source":["def Modified_Overlapping_MultiSurf(scaledX, scaledY, C,classProb,numUpdates, categoricalX, kernelWidth):\n","  \n","  # MultiSurf for classification\n","  numInstances,numAttr = scaledX.shape \n","  attrWeights = np.zeros(numAttr) \n","  # C is boolean 2D matrix of size (N, Ngrp) i.e. (Number of instances vs Number of classes)\n","  numClasses = C.shape[1]   # Ngrp\n","\n","  # Choose the random instances\n","  np.random.seed(123) \n","  rndIdx = np.random.choice(numInstances, numUpdates, replace=False)   # random indices of m instances from total of n instances\n","  idxVec = np.arange(numInstances)   # [0 .. N-1]\n","\n","   # Make searcher objects, one object per class. \n","  instIdxPerClass = {}  \n","  for c in range(numClasses):\n","    c_C = C[:,c]\n","    instIdxPerClass[c] = np.array([i for i in range(len(c_C)) if c_C[i]], dtype=int)   # instances of class c\n","  \n","  # selecting distance function\n","  distFunc = 'manhattan'\n","  if categoricalX:\n","    distFunc = 'hamming'\n","  else: \n","    distFunc = 'manhattan'\n","  \n","  pairwiseDistance = pair_dist(scaledX, metric=distFunc)\n","\n","   # Outer loop, for updating attribute weights iteratively\n","  for i in range(numUpdates):\n","    targetIdx = rndIdx[i]\n","    \n","      # Choose the correct random observation\n","    targetInst = scaledX[targetIdx,:]\n","\n","      # Find the class for this observation\n","    targetC = C[targetIdx, :]\n","    thisC = scaledY[targetIdx] # taking the class of target instance\n","    \n","    # find nearest hits and misses\n","    allInstIdx = np.arange(numInstances)\n","    otherIdxExceptTarget = allInstIdx[allInstIdx!=targetIdx] \n","    meanDistance = np.mean(pairwiseDistance[targetIdx][otherIdxExceptTarget])\n","    stdDistance = np.std(pairwiseDistance[targetIdx][otherIdxExceptTarget])\n","    threshold = meanDistance - (stdDistance/2.0)\n","    # print('threshold : ' ,threshold)\n","    Hits = np.array([], dtype = 'int')\n","    allMissesInd = np.array([], dtype = 'int')\n","    Misses = {}\n","    \n","    for j in range(numInstances): \n","      newC = scaledY[j]\n","      if pairwiseDistance[targetIdx][j] < threshold:\n","        if newC == thisC and j != targetIdx:\n","          Hits = np.append(Hits, j)\n","        elif newC != thisC:\n","          allMissesInd =  np.append(allMissesInd, j)\n","          if newC in Misses:\n","            Misses[newC] = np.append(Misses[newC], j)\n","          else:\n","            Misses[newC] = np.array([j], dtype= 'int')\n","\n","    neighbourIndicesFromOtherClass = {}\n","    for c in range(numClasses):\n","      neighbourIndicesFromOtherClass[c] = np.append(allMissesInd[ scaledY[allMissesInd] != c ], np.append(Hits, targetIdx))\n","\n","    # Misses = np.array(Misses)\n","    # print('targetID :',targetIdx)\n","    # print('HitId :', Hits)\n","    # print('MissId :', Misses)\n","    \n","    #***************** ATTRIBUTE UPDATE *****************************\n","    # Inner loop to update weights for each attribute:\n","\n","    # print('targetID :',targetIdx)\n","    # print(\"target :\",targetInst)\n","    # print('HitId :', Hits)\n","    # print(\"Hit :\", X[Hits])\n","    # print('MissId :', Misses[:, 0:-1])\n","    # print(\"Miss :\", X[Misses[:, 0:-1]])\n","    \n","    for j in range(numAttr):\n","      dH = diffH(j,scaledX,targetIdx,Hits, allMissesInd, categoricalX, kernelWidth)/numUpdates\n","      # print('dH', dH) \n","      dM = diffM(j,scaledX,targetIdx, Misses, neighbourIndicesFromOtherClass, len(allMissesInd), categoricalX, classProb, kernelWidth)/numUpdates\n","      # print('dM', dM)\n","      attrWeights[j] = attrWeights[j] - (dH * (1 - classProb[thisC]))  + (dM * classProb[thisC])\n","      \n","      #****************************************************************\n","    \n","    # print('attrWeights : ', attrWeights)\n","  \n","  return attrWeights    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLkuPu0v2tRo"},"source":["def cityblock(thisX, X):\n","  d = abs(X - thisX) \n","  return d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-2iwGin2tdA"},"source":["def hamming(thisX, X):\n","  d = (X != thisX).astype(int) \n","  return d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n82B1ENSQ8Uy"},"source":["def kernel_func(d, kernelWidth):\n","  return np.exp(-d/kernelWidth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dqmk6IaBJoDy"},"source":["#--------------------------------------------------------------------------\n","# DIFFH (for Modified_Overlapping_MultiSurfClass): Function to calculate difference measure\n","# for an attribute between the selected instance and its hits\n","\n","def diffH(a, X, targetIdx, Hits, missesInd, categoricalX, kernelWidth):\n","\n","  # print(a, targetIdx, Hits, categoricalX)\n","\n","  # If no hits, return zero by default\n","  if not len(Hits):\n","      return 0\n","\n","  distFunc = hamming if categoricalX else cityblock \n","\n","  if len(missesInd) <= 0:\n","    distMeas = np.ones(len(Hits)) * distFunc(X[targetIdx, a], X[Hits,a])\n","    return distMeas.sum()/ len(Hits)\n","\n","\n","  # Calculate weighted sum of distances\n","\n","  distMeas = 0\n","  totalPNotInOverlapping = 0\n","\n","  distMetric = 'manhattan'\n","  if categoricalX:\n","    distMetric = 'hamming'\n","  else: \n","    distMetric = 'manhattan'\n","\n","  disttoMissesFromHits = np.sum(kernel_func(pair_dist(np.expand_dims(X[Hits, a], axis = 1), np.expand_dims(X[missesInd,a], axis = 1), metric = distMetric), kernelWidth), axis = 1)\n","  \n","  distToOtherHits = pair_dist(np.expand_dims(X[np.append(Hits, targetIdx), a], axis = 1), metric = distMetric)\n","  distToOtherHits = distToOtherHits[~np.eye(distToOtherHits.shape[0], dtype = bool)].reshape(distToOtherHits.shape[0],-1)\n","  distToOtherHits = distToOtherHits[:-1]\n","  distToOtherHits = np.sum(kernel_func(distToOtherHits, kernelWidth), axis = 1)\n","  pNotInOverlapping = 1 -  disttoMissesFromHits/ (disttoMissesFromHits + distToOtherHits)\n","\n","  distMeas = pNotInOverlapping * distFunc(X[targetIdx, a], X[Hits,a])\n","  distMeas = distMeas.sum()\n","\n","  totalPNotInOverlapping = pNotInOverlapping.sum()\n","\n","  if totalPNotInOverlapping>0:\n","    return distMeas/totalPNotInOverlapping\n","  else:\n","   return distMeas\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4GnfgMhlprOx"},"source":["#--------------------------------------------------------------------------\n","# DIFFM (for Modified_Overlapping_MultiSurfClass) : Function to calculate difference measure\n","# for an attribute between the selected instance and its misses\n","def diffM(a, X, targetIdx, Misses, neighbourIndicesFromOtherClass, totalMisses, categoricalX, classProb, kernelWidth):\n","  \n","  # print(a, targetIdx, Misses, categoricalX)\n","\n","  # print('missesInd = ', missesInd)\n","\n","  # If no hits, return zero by default\n","  if not totalMisses:\n","      return 0.0\n","\n","  # Calculate weighted sum of distances\n","  distFunc = hamming if categoricalX else cityblock \n","\n","  distMeas = 0.0\n","  totalPNotInOverlapping = 0.0\n","\n","  distMetric = 'manhattan'\n","  if categoricalX:\n","    distMetric = 'hamming'\n","  else: \n","    distMetric = 'manhattan'\n","\n","  for cls, missIdx in Misses.items():\n","    missIdx = missIdx.astype(int)\n","    \n","    if len(missIdx) > 0:\n","      pNotInOverlapping = np.ones(len(missIdx))\n","\n","      if len(neighbourIndicesFromOtherClass[cls]) > 0:\n","        distToOtherClassIndices = np.sum(kernel_func(pair_dist(np.expand_dims(X[missIdx, a], axis = 1), np.expand_dims(X[neighbourIndicesFromOtherClass[cls],a], axis = 1), metric = distMetric), kernelWidth), axis = 1)\n","        \n","        distToOtherMissesFromSameClass = pair_dist(np.expand_dims(X[missIdx, a], axis = 1), metric = distMetric)\n","        distToOtherMissesFromSameClass = distToOtherMissesFromSameClass[~np.eye(distToOtherMissesFromSameClass.shape[0], dtype = bool)].reshape(distToOtherMissesFromSameClass.shape[0],-1)\n","        distToOtherMissesFromSameClass = np.sum(kernel_func(distToOtherMissesFromSameClass, kernelWidth), axis = 1)\n","        \n","        pNotInOverlapping = 1 - distToOtherClassIndices/(distToOtherClassIndices + distToOtherMissesFromSameClass) \n","    \n","      distMeas += np.sum(pNotInOverlapping * distFunc(X[targetIdx, a], X[missIdx,a]) * (len(missIdx)/totalMisses) * len(Misses))\n","      totalPNotInOverlapping += pNotInOverlapping.sum()\n","\n","  if totalPNotInOverlapping>0:\n","    return distMeas/totalPNotInOverlapping\n","  else:\n","   return distMeas"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w40aIoG-Ae28"},"source":["# #--------------------------------------------------------------------------\n","# # DIFFH (for Modified_Overlapping_MultiSurfClass): Function to calculate difference measure\n","# # for an attribute between the selected instance and its hits\n","\n","# def diffH(a, X, targetIdx, Hits, missesInd, categoricalX, kernelWidth):\n","\n","#   # print(a, targetIdx, Hits, categoricalX)\n","\n","#   # If no hits, return zero by default\n","#   if not len(Hits):\n","#       return 0\n","\n","#   # Calculate weighted sum of distances\n","#   distFunc = hamming if categoricalX else cityblock \n","\n","#   distMeas = 0\n","#   totalPNotInOverlapping = 0\n","\n","#   for hit in Hits:  \n","#     otherHits = np.append(Hits[Hits != hit], targetIdx)\n","#     # totalNeighbours = np.append(otherHits, missesInd)\n","#     # pNotInOverlapping is the probability of a neighbour not being in an overlapping area\n","#     pNotInOverlapping = 1\n","#     if len(missesInd)>0:\n","#       distToMisses = np.sum(kernel_func(distFunc(X[hit, a], X[missesInd,a]), kernelWidth))\n","#       distToOtherHits = np.sum(kernel_func(distFunc(X[hit, a], X[otherHits,a]), kernelWidth))\n","#       pNotInOverlapping = 1 -  distToMisses/ (distToMisses + distToOtherHits)\n","#     distMeas += pNotInOverlapping * distFunc(X[targetIdx, a], X[hit,a])\n","#     totalPNotInOverlapping += pNotInOverlapping\n","\n","#   # print('For attribute ',a,' Hit distmeas : ', distMeas/len(Hits))\n","\n","#   if totalPNotInOverlapping>0:\n","#     return distMeas/totalPNotInOverlapping\n","#   else:\n","#    return distMeas\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Rb0WZu42j7T"},"source":["# #--------------------------------------------------------------------------\n","# # DIFFM (for Modified_Overlapping_MultiSurfClass) : Function to calculate difference measure\n","# # for an attribute between the selected instance and its misses\n","# def diffM(a, X, targetIdx, Hits, Misses, missesInd, categoricalX, classProb, kernelWidth):\n","  \n","#   # print(a, targetIdx, Misses, categoricalX)\n","\n","#   # print('missesInd = ', missesInd)\n","\n","#   # If no hits, return zero by default\n","#   if not len(missesInd):\n","#       return 0\n","\n","#   # Calculate weighted sum of distances\n","#   distFunc = hamming if categoricalX else cityblock \n","\n","#   distMeas = 0\n","#   totalPNotInOverlapping = 0\n","#   # for missIdx in Misses.values():\n","#   #   for miss in missIdx:\n","#   #     otherMisses = missIdx[missIdx != miss]\n","#   #     totalNeighbours = np.append(missesInd[missesInd!=miss], Hits)\n","#   #     # pNotInOverlapping is the probability of a neighbour not being in an overlapping area\n","#   #     pNotInOverlapping = np.sum(kernel_func(distFunc(X[miss, a], X[otherMisses,a]), kernelWidth)) / np.sum(kernel_func(distFunc(X[miss, a], X[totalNeighbours,a]), kernelWidth))\n","#   #     distMeas += pNotInOverlapping * distFunc(X[targetIdx, a], X[miss,a])\n","#   #     totalPNotInOverlapping += pNotInOverlapping\n","\n","#   totalMisses = len(missesInd)\n","\n","#   Hits = np.append(Hits, targetIdx)\n","#   for missIdx in Misses.values():\n","#     missIdx = missIdx.astype(int)\n","#     for miss in missIdx:\n","#       otherMissesFromSameClass = missIdx[missIdx != miss]\n","#       totalNeighbours = np.append(missesInd[missesInd!=miss], Hits).astype(int)\n","#       otherClassInd = np.array([ind for ind in totalNeighbours if ind not in otherMissesFromSameClass], dtype= 'int')\n","#       # if not otherClassInd.shape[0]:\n","#       #   print('otherClassInd = ',otherClassInd)\n","#       # pNotInOverlapping is the probability of a neighbour not being in an overlapping area\n","#       pNotInOverlapping = 1\n","#       if len(otherClassInd)>0:\n","#         distToOtherClassIndices = np.sum(kernel_func(distFunc(X[miss, a], X[otherClassInd,a]), kernelWidth))\n","#         distToOtherMissesFromSameClass = np.sum(kernel_func(distFunc(X[miss, a], X[otherMissesFromSameClass,a]), kernelWidth))\n","#         pNotInOverlapping = 1 - distToOtherClassIndices/(distToOtherClassIndices + distToOtherMissesFromSameClass) \n","#       # if pNotInOverlapping==0:\n","#       #   print('pNotInOverlapping = ',pNotInOverlapping)      \n","\n","#       # Explanation: first we are calculating pNotInOverlapping * distFunc(X[targetIdx, a], X[miss,a]) for each instance in a class.\n","#       # So now we have the measurement in  all instance of a single class scale.\n","#       # Then we take the summation of  probability of each class and the sum value of pNotInOverlapping * distFunc(X[targetIdx, a], X[miss,a]) of that class,\n","#       #  that means pNotInOverlapping * distFunc(X[targetIdx, a], X[miss,a]) * (len(missIdx)/totalMisses) .\n","#       # Now we have measuremnts for a single class and all instance for it(suppose). Then we multiply it by number of Miss classes, len(Misses) and rescale the measurement \n","#       # for all classes andd all miss instances.\n","#       # Finally, we devide the measurement by totalPNotInOverlapping, which bring it back in one instance scale.\n","      \n","#       distMeas += pNotInOverlapping * distFunc(X[targetIdx, a], X[miss,a]) * (len(missIdx)/totalMisses) * len(Misses)\n","#       totalPNotInOverlapping += pNotInOverlapping\n","\n","#   # print('For attribute ',a,' Misses distmeas : ', distMeas/len(Misses))\n","#   # if totalPNotInOverlapping==0:\n","#   #   print('totalPNotInOverlapping = ',totalPNotInOverlapping)\n","#   if totalPNotInOverlapping>0:\n","#     return distMeas/totalPNotInOverlapping\n","#   else:\n","#    return distMeas"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_KvKl7P4MlRZ"},"source":["### Run feature selection"]},{"cell_type":"code","metadata":{"id":"aOX0asWFteMH"},"source":["# from sklearn.datasets import load_iris, load_digits, load_wine\n","# X, Y = load_digits(return_X_y= True)\n","# print('dataset: digits')\n","# ranked, weight = Modified_Overlapping_MultiSurf_configure(X,Y,K=10,prior='uniform', numUpdates='all', categoricalX='off')\n","# print(ranked, weight)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"24fjwbzxuzBa"},"source":["# X = np.array([[0,0,0,0,1,0,0],\n","#               [0,1,0,1,0,1,0],\n","#               [1,0,0,0,1,1,0],\n","#               [0,0,0,1,0,0,0],\n","#               [1,1,0,0,0,0,0],\n","#               [0,1,0,0,1,0,0],\n","#               [0,0,0,0,0,1,0],\n","#               [1,0,0,1,0,0,0],\n","#               [1,0,1,0,0,0,1],\n","#               [1,1,0,0,1,0,1],\n","#               [0,0,0,0,0,0,1],\n","#               [1,0,1,1,1,1,1],\n","#               [1,0,0,0,0,0,0],\n","#               [1,0,0,1,0,1,1],\n","#               [0,1,1,0,0,0,0],\n","#               [0,0,1,1,0,0,1],\n","#               [1,1,0,1,0,0,0],\n","#               [1,0,1,0,1,0,1],\n","#               [0,1,1,1,0,0,1],\n","#               [1,1,1,1,1,1,1]])\n","\n","# Y = np.array([0,1,1,0,0,1,0,1,1,0,0,1,1,1,1,0,0,1,1,0])\n","\n","# Overlapping_MultiSurf_configure(X,Y,K=3,prior='uniform', numUpdates='all', categoricalX='on')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQe2rjPuiyP5"},"source":["# X = np.array([[1,0,1],\n","#               [1,0,0],\n","#               [0,1,1],\n","#               [0,1,0],\n","#               [0,0,1],\n","#               [0,0,0],\n","#               [1,1,1],\n","#               [1,1,0]])\n","\n","# Y = np.array([1,1,1,1,0,0,0,0])\n","# ranked, weight= Modified_Overlapping_MultiSurf_configure(X,Y,K=1,prior='uniform', numUpdates='all', categoricalX='on')\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQgt2FhDQL5a"},"source":["# def permute(x):\n","#   if len(x) == 7:\n","#     global X\n","#     global Y\n","#     Y.append((x[0] ^ x[6]))\n","#     X.append(x)\n","#     return\n","#   x = np.append(x,0)\n","#   permute(x)\n","#   x = x[0:-1]\n","#   x = np.append(x,1)\n","#   permute(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLcbYBwbXmAd"},"source":["# X = []\n","# Y = []\n","# x = np.array([], dtype=int)\n","# permute(x)\n","# X = np.array(X)\n","# Y = np.array(Y)\n","# ranked, weight=Overlapping_MultiSurf_configure(X,Y,prior='uniform', numUpdates=len(Y)/2, categoricalX='on',kernelWidth = 3)\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6g9wkOs_fTTi"},"source":["# !pip install skrebate\n","# from skrebate import ReliefF, MultiSURF, SURF, SURFstar\n","# import time\n","\n","\n","# # test classification dataset\n","# from sklearn.datasets import make_classification\n","# # define dataset\n","# X, Y = make_classification(n_samples=100, n_features=15, n_informative=10, n_redundant=0,shuffle=False, random_state=1)\n","# # summarize the dataset\n","# print(X.shape, Y.shape)\n","# start = time.time()\n","# ranked, weight= Modified_Overlapping_MultiSurf_configure(X,Y,prior='uniform', numUpdates='all', categoricalX='off', kernelWidth = 3)\n","# print(\"Modified_Overlapping_MultiSurf Runtime : \", time.time() - start)\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)\n","\n","# # From ReBATE Framework - ReliefF\n","# start = time.time()\n","# reliefF = ReliefF(n_features_to_select=min(X.shape[1]-50, 50), n_neighbors= 10)\n","# reliefF.fit(X, Y)\n","# weight = reliefF.feature_importances_\n","# ranked = reliefF.top_features_\n","# print(\"ReBATE ReliefF Runtime : \", time.time() - start)\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)\n","\n","# # From ReBATE Framework - Modified_Overlapping_MultiSurf\n","# start = time.time()\n","# MultiSURF = MultiSURF(n_features_to_select=min(X.shape[1]-50, 50))\n","# MultiSURF.fit(X, Y)\n","# weight = MultiSURF.feature_importances_\n","# ranked = MultiSURF.top_features_\n","# print(\"ReBATE MultiSURF Runtime : \", time.time() - start)\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9JepB5WCcx-c"},"source":["# import time\n","# a = np.array([[1,1,1],[2,2,2], [3,3,3], [0,0,0]])\n","# start = time.time()\n","# c = pair_dist(a, metric='manhattan')\n","# print(time.time()-start)\n","# print(c,'\\n')\n","# start = time.time()\n","# d = pdist(a, metric='cityblock')\n","# f = squareform(d)\n","# print(time.time()-start)\n","# print(d)\n","# print(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OIvEmbQWaHEL"},"source":["# from sklearn.datasets import load_iris, load_digits, load_wine\n","\n","# X, Y = load_iris(return_X_y= True)\n","# print(X.shape, Y.shape)\n","# ranked, weight= Modified_Overlapping_MultiSurf_configure(X,Y,prior='uniform', numUpdates='all', categoricalX='off', kernelWidth = 3)\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XeagnPBvpR-2"},"source":["# (100, 15) (100,)\n","# Modified_Overlapping_MultiSurf Runtime :  5.090434551239014\n","# ranked\n","# [ 7  6  3  0  1  2  8  5  4  9 11 13 12 14 10]\n","# weight\n","# [ 0.0094149   0.00860712  0.00561274  0.02045952  0.00149776  0.00177346\n","#   0.02341063  0.03550037  0.00355158 -0.00319182 -0.01328158 -0.00752251\n","#  -0.0080434  -0.00762857 -0.012672  ]\n","# ReBATE ReliefF Runtime :  0.1096644401550293\n","# ranked\n","# [ 7  6  3  0  1  2  4  8  5  9 13 11 12 14 10]\n","# weight\n","# [ 0.03027158  0.02944122  0.02100642  0.0466252   0.01473765  0.01230972\n","#   0.05677486  0.08102311  0.01446427  0.00632119 -0.02152517 -0.00379137\n","#  -0.00407784  0.00101088 -0.00530084]\n","# ReBATE MultiSURF Runtime :  0.1627180576324463\n","# ranked\n","# [ 7  6  3  0  1  2  8  5  4  9 11 13 12 14 10]\n","# weight\n","# [ 0.01821793  0.01646602  0.01074347  0.03995023  0.00250348  0.00312992\n","#   0.04543218  0.06934124  0.00663548 -0.00648229 -0.02624685 -0.01500524\n","#  -0.0160485  -0.01518648 -0.02520969]\n","\n","# (150, 4) (150,)\n","# ranked\n","# [3 2 0 1]\n","# weight\n","# [-0.06336539 -0.07027905 -0.00653049 -0.00160689]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ShubSVyawAnU"},"source":["# X = np.array([[6,7,8],[3,0,5], [1,2,3]])\n","# newX = np.expand_dims(X, axis = 2)\n","# print(newX)\n","# print(newX.shape)\n","\n","# for i in range(newX.shape[0]):\n","#   print(pair_dist(newX[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvBMx-cTwGh8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618339126911,"user_tz":-360,"elapsed":1516,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}},"outputId":"244b9209-707b-498c-89fa-b2a1353ef9a1"},"source":["# # X= np.array([[-2,-1],[-1,0],[0,1],[1,2],[2,4],[3,6],[6,8],[4,5],[7,7],[8,9],[9,10],[10,11],[11,12],[12,13]])\n","# # X= np.array([[-2,-1],[-1,0],[0,1],[1,2],[2,4],[3,6],[4,8],[6,5],[7,7],[8,9],[9,10],[10,11],[11,12],[12,13]])\n","# X= np.array([[4,1.2],[4.4,1.4],[4.8,1.8],[4.9,2.5],[5.1,2.9],[5.4,4.5],[6.1,7.3],[5.9,6.5],[6.4,8.9],[6.8,10.9],[7.1,11.1],[7.2,11.5],[7.5,12],[7.8,12.3]])\n","# Y= np.array([1,1,1,1,1,1,1,2,2,2,2,2,2,2])\n","# ranked, weight =Modified_Overlapping_MultiSurf_configure(X,Y,prior='uniform', numUpdates='all', categoricalX='off', kernelWidth = 3)\n","# print(ranked, weight)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1 0] [-0.06852642 -0.05820509]\n"],"name":"stdout"}]}]}