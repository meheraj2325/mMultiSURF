{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"Relief.ipynb","provenance":[{"file_id":"1RHS6ELJYsVTxnbq2lh-pQXUWLlZmd_Zn","timestamp":1601128901072}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"a6utNr_2Ae1g"},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.neighbors import NearestNeighbors\n","import pandas as pd\n","import math"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHaRYqCnykZz"},"source":["def check_numeric(X):\n","  newX = np.array(X).reshape(-1)\n","  return all(not isinstance(n, str) for n in newX)\n","\n","# X=np.array([[6,7,8],[3,0,5]])\n","# print(check_numeric(X))\n","# print(X)\n","# print(check_numeric([1,2,3]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n4lcmIQvsn6Q"},"source":["def error_return(p):\n","  ranked = np.arange(p, dtype=int) \n","  weight = np.empty((1,p))\n","  weight = np.squeeze(weight) \n","  weight[:] = np.nan\n","  return ranked, weight"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MDCPZoSWJzf9"},"source":["\n","### Preprocessing data and call feature selection algorithm"]},{"cell_type":"code","metadata":{"id":"FToEQpI3J5gK"},"source":["def Relief_configure(X,Y, **kwargs):\n","  X = np.array(X)\n","  Y = np.array(Y)\n","  numUpdates, categoricalX = kwargs['numUpdates'], kwargs['categoricalX']\n","  K = 1 # number of nearest neighbours\n","\n","  # if not check_numeric(X):\n","  #   print('X does not contain numeric data')\n","  #   p = X.shape[1] # no of attributes\n","  #   return error_return(p) \n","\n","  # Check if the input sizes are consistent\n","  if Y.shape[0] != X.shape[0]:\n","    print('number of instances and output labels doesnot match')\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","  \n","  # converting classes as 0 to #classes\n","  [Y, grp] = pd.factorize(Y)\n","\n","  # grpToInd contains class to index mapping, grpToInd[className]= ind\n","  grpToInd={}\n","  for ind, g in enumerate(grp):\n","    grpToInd[g]= ind\n","\n","  # removing incomplete instances\n","  # df_XY = pd.DataFrame(X)\n","  # df_XY['Y'] = Y\n","  # df_XY = df_XY.dropna()\n","  # X, Y = np.array(df_XY.iloc[:, 0:-1]), np.array(df_XY.iloc[:, -1])\n","\n","  Ngrp = len(grp)\n","  N = X.shape[0]\n","  C = np.zeros((N,Ngrp))\n","  C[np.arange(N), Y] = True\n","  \n","  # Checking the number of classes\n","  if Ngrp>2:\n","    print('Number of classes exceed 2')\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","\n","  #  Do we have enough observations?\n","  if len(Y)<2:\n","    print('not enough instances')\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","\n","  # Check number of updates\n","  if (not numUpdates=='all') and (not check_numeric([numUpdates]) or numUpdates<=0):\n","    print('numUpdates is invalid')\n","  elif (not numUpdates) or numUpdates=='all':\n","    numUpdates = X.shape[0]\n","  else:\n","    numUpdates = math.ceil(numUpdates)\n","    \n","  # Check the type of categoricalX\n","  if not categoricalX or (categoricalX != 'on' and categoricalX != 'off'):\n","      print('categoricalX is invalid')\n","  categoricalX = (categoricalX == 'on')   \n","\n","  # Find max and min for every predictor\n","  p = X.shape[1] # no of attributes\n","  Xmax = X.max(0)\n","  Xmin = X.min(0) \n","  Xdiff = Xmax - Xmin\n","  Xmean = np.mean(X, axis=0) \n","\n","  # Exclude single-valued attributes\n","  isDiffValue = Xdiff >= 1e-9  # boolean array of size #attributes [1,0,0,0]\n","  if not any(isDiffValue):\n","    print(\"All attributes are single valued attributes.\")\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","  \n","  X = X[:, isDiffValue ] \n","  Xmax = Xmax[isDiffValue] \n","  Xmin = Xmin[isDiffValue]\n","  Xdiff = Xdiff[isDiffValue] \n","  Xmean = Xmean[isDiffValue] \n","  rejected = [ i for i in range(len(isDiffValue)) if not isDiffValue[i]]  # indices of the deleted attributes (values range from 1 to p)\n","  accepted = [ i for i in range(len(isDiffValue)) if isDiffValue[i]]  # indices of remaining attributes (values range from 1 to p)\n","\n","  # Scale and center the attributes\n","  if not categoricalX:\n","      X = (X - Xmin) / Xdiff \n","\n","  # The #updates cannot be more than the #observations\n","  numUpdates = min(numUpdates, X.shape[0])\n","\n","  # Call Relief. By default all weights are set to NaN.\n","  weight = np.empty(p) \n","  weight[:] = np.nan\n","\n","  weight[accepted] = Relief(X,C,numUpdates,K,categoricalX) \n","\n","  # Assign ranks to attributes\n","  sorted = np.argsort(-weight[accepted])\n","  accepted = np.array(accepted)\n","  ranked = accepted[sorted]\n","  ranked = np.append(ranked, rejected)\n","  ranked = ranked.astype(int)\n","\n","  return ranked, weight\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6a1zuATsNfV1"},"source":["# Relief algorithm function"]},{"cell_type":"code","metadata":{"id":"1qwWjfJzAe2u"},"source":["def Relief(scaledX,C,numUpdates,K,categoricalX):\n","  \n","  # Relief for classification\n","  numInstances,numAttr = scaledX.shape \n","  attrWeights = np.zeros(numAttr) \n","  # C is boolean 2D matrix of size (N, Ngrp) i.e. (Number of instances vs Number of classes)\n","  numClasses = C.shape[1]   # Ngrp\n","\n","   # Choose the random instances\n","  np.random.seed(123) \n","  rndIdx = np.random.choice(numInstances, numUpdates, replace=False)   # random indices of m instances from total of n instances\n","  idxVec = np.arange(numInstances)   # [0 .. N-1]\n","\n","   # Make searcher objects, one object per class. \n","  instIdxPerClass = {}  \n","  for c in range(numClasses):\n","      c_C = C[:,c]\n","      instIdxPerClass[c] = np.array([i for i in range(len(c_C)) if c_C[i]])   # instances of class c\n","  \n","  # selecting distance function\n","  distFunc = 'manhattan'\n","  if categoricalX:\n","    distFunc = 'hamming'\n","  else: \n","    distFunc = 'manhattan'\n","  \n","   # Outer loop, for updating attribute weights iteratively\n","  for i in range(numUpdates):\n","    targetIdx = rndIdx[i]\n","    \n","      # Choose the correct random observation\n","    targetInst = scaledX[targetIdx,:]\n","\n","      # Find the class for this observation\n","    targetC = C[targetIdx, :]\n","    thisC = np.array([i for i in range(len(targetC)) if targetC[i]]).item() # taking the class of target instance\n","    \n","      # Find the k-nearest hits \n","    sameClassIdx = instIdxPerClass[thisC] \n","    \n","      # we may not always find numNeighbor Hits\n","    lenHits = min(len(sameClassIdx)-1,K) \n","\n","      # find nearest hits\n","      # It is not guaranteed that the first hit is the same as targetIdx. Since\n","      # they have the same class, it does not matter. If we add observation\n","      # weights in the future, we will need here something similar to what we\n","      # do in ReliefReg.\n","    # print('HitFit : ', scaledX[sameClassIdx])\n","    Hits = [] \n","    if lenHits>0:\n","        nearestNeighborHits = NearestNeighbors(n_neighbors=lenHits+1, algorithm='auto', metric= distFunc).fit(scaledX[sameClassIdx])\n","        idxH = nearestNeighborHits.kneighbors([targetInst], lenHits+1, return_distance=False)\n","        idxH = np.squeeze(idxH)\n","        Hits = sameClassIdx[idxH[1:]] \n","\n","      # Process misses\n","    missClass = [i for i in range(len(targetC)) if not targetC[i]]\n","    Misses = [] \n","    \n","    if len(missClass):  # Make sure there are misses!\n","          # Find the k-nearest misses Misses(C,:) for each class C ~= class(targetInst)\n","          # Misses will be of size (no. of classes -1)x(K)\n","        Misses = np.empty((numClasses-1, min(numInstances,K+1)), dtype= int)   # last column has class index\n","        Misses[:] = -1\n","\n","        for mi in range(len(missClass)):\n","            \n","              # find all observations of this miss class\n","            missClassIdx = instIdxPerClass[missClass[mi]]\n","            \n","              # we may not always find K misses\n","            lenMiss = min(len(missClassIdx),K) \n","            \n","            # print('Missfit :', scaledX[missClassIdx])\n","\n","              # find nearest misses\n","            if lenMiss>0:\n","              nearestNeighborMiss = NearestNeighbors(n_neighbors=lenMiss, algorithm='auto', metric= distFunc).fit(scaledX[missClassIdx])\n","              idxM = nearestNeighborMiss.kneighbors([targetInst], lenMiss, return_distance=False)\n","              idxM = np.squeeze(idxM)\n","              Misses[mi, 0:lenMiss] = missClassIdx[idxM]\n","        \n","          # Misses contains obs indices for miss classes, sorted by dist.\n","        Misses[:,-1] = missClass \n","            \n","      #***************** ATTRIBUTE UPDATE *****************************\n","      # Inner loop to update weights for each attribute:\n","\n","    # print('targetID :',targetIdx)\n","    # print(\"target :\",targetInst)\n","    # print('HitId :', Hits)\n","    # print(\"Hit :\", X[Hits])\n","    # print('MissId :', Misses[:, 0:-1])\n","    # print(\"Miss :\", X[Misses[:, 0:-1]])\n","    \n","    for j in range(numAttr):\n","        dH = diffH(j,scaledX,targetIdx,Hits, categoricalX)/numUpdates\n","        # print('dH', dH) \n","        dM = diffM(j,scaledX,targetIdx,Misses,categoricalX)/numUpdates\n","        # print('dM', dM)\n","        attrWeights[j] = attrWeights[j] - dH + dM \n","      \n","      #****************************************************************\n","\n","  return attrWeights    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLkuPu0v2tRo"},"source":["def cityblock(thisX, X):\n","  d = abs(X - thisX) \n","  return d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-2iwGin2tdA"},"source":["def hamming(thisX, X):\n","  d = (X != thisX).astype(int) \n","  return d\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w40aIoG-Ae28"},"source":["#--------------------------------------------------------------------------\n","# DIFFH (for ReliefClass): Function to calculate difference measure\n","# for an attribute between the selected instance and its hits\n","\n","def diffH(a, X, targetIdx, Hits, categoricalX):\n","\n","  # print(a, targetIdx, Hits, categoricalX)\n","\n","  distMeas = 0 \n","\n","  # If no hits, return zero by default\n","  if not len(Hits):\n","      return distMeas\n","\n","  # Calculate weighted sum of distances\n","  if categoricalX:\n","    distMeas = np.sum(hamming(X[targetIdx, a], X[Hits,a]))\n","  else:\n","    distMeas = np.sum(cityblock(X[targetIdx, a], X[Hits,a]))\n","\n","  # print('Hit distmeas : ', distMeas/len(Hits))\n","\n","  return distMeas/len(Hits)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Rb0WZu42j7T"},"source":["#--------------------------------------------------------------------------\n","# DIFFM (for ReliefClass) : Function to calculate difference measure\n","# for an attribute between the selected instance and its misses\n","def diffM(a, X, targetIdx, Misses, categoricalX):\n","  distMeas = 0 \n","  MissWithoutC = Misses[:, 0:-1]\n","  # If no misses, return zero\n","  if not len(Misses):\n","    return distMeas\n","\n","  # Loop over misses\n","  for mi in range(Misses.shape[0]):\n","    ismiss = (Misses[mi, 0:-1] != -1) \n","    \n","    if any(ismiss):\n","        cls = Misses[mi,-1] \n","        nmiss = np.sum(ismiss)           \n","\n","        if categoricalX:\n","          distMeas = distMeas + (np.sum(hamming(X[targetIdx, a], X[MissWithoutC[mi, ismiss], a]))/nmiss)\n","        else:\n","          distMeas = distMeas + (np.sum(cityblock(X[targetIdx, a], X[MissWithoutC[mi,ismiss], a]))/nmiss)\n","\n","  # print('Miss distmeas : ', distMeas)\n","\n","  return distMeas\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"24fjwbzxuzBa"},"source":["# X = np.array([[0,0,0,0,1,0,0],\n","#               [0,1,0,1,0,1,0],\n","#               [1,0,0,0,1,1,0],\n","#               [0,0,0,1,0,0,0],\n","#               [1,1,0,0,0,0,0],\n","#               [0,1,0,0,1,0,0],\n","#               [0,0,0,0,0,1,0],\n","#               [1,0,0,1,0,0,0],\n","#               [1,0,1,0,0,0,1],\n","#               [1,1,0,0,1,0,1],\n","#               [0,0,0,0,0,0,1],\n","#               [1,0,1,1,1,1,1],\n","#               [1,0,0,0,0,0,0],\n","#               [1,0,0,1,0,1,1],\n","#               [0,1,1,0,0,0,0],\n","#               [0,0,1,1,0,0,1],\n","#               [1,1,0,1,0,0,0],\n","#               [1,0,1,0,1,0,1],\n","#               [0,1,1,1,0,0,1],\n","#               [1,1,1,1,1,1,1]])\n","\n","# Y = np.array([0,1,1,0,0,1,0,1,1,0,0,1,1,1,1,0,0,1,1,0])\n","\n","# Relief_configure(X,Y,K=3,prior='uniform', numUpdates='all', categoricalX='on')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQe2rjPuiyP5"},"source":["# X = np.array([[1,0,1],\n","#               [1,0,0],\n","#               [0,1,1],\n","#               [0,1,0],\n","#               [0,0,1],\n","#               [0,0,0],\n","#               [1,1,1],\n","#               [1,1,0]])\n","\n","# Y = np.array([1,1,1,1,0,0,0,0])\n","# ranked, weight= Relief_configure(X,Y,K=1,prior='uniform', numUpdates='all', categoricalX='on')\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQgt2FhDQL5a"},"source":["# def permute(x):\n","#   if len(x) == 7:\n","#     global X\n","#     global Y\n","#     Y.append((x[0] ^ x[1]))\n","#     X.append(x)\n","#     return\n","#   x = np.append(x,0)\n","#   permute(x)\n","#   x = x[0:-1]\n","#   x = np.append(x,1)\n","#   permute(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLcbYBwbXmAd"},"source":["# X = []\n","# Y = []\n","# x = np.array([], dtype=int)\n","# permute(x)\n","# X = np.array(X)\n","# Y = np.array(Y)\n","# ranked, weight=Relief_configure(X,Y, numUpdates='all', categoricalX='on')\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6g9wkOs_fTTi"},"source":["# # test classification dataset\n","# from sklearn.datasets import make_classification\n","# # define dataset\n","# X, Y = make_classification(n_samples=100, n_features=8, n_informative=3, n_redundant=0,shuffle=False, random_state=1)\n","# # summarize the dataset\n","# print(X.shape, Y.shape)\n","# ranked, weight= Relief_configure(X,Y,K=10,prior='uniform', numUpdates='all', categoricalX='off')\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)"],"execution_count":null,"outputs":[]}]}