{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"IRelief2.ipynb","provenance":[{"file_id":"171u4z4vjw6Dwf0Xy2uDeWM8ZqNeDggnx","timestamp":1601979298039},{"file_id":"1RHS6ELJYsVTxnbq2lh-pQXUWLlZmd_Zn","timestamp":1601128901072}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"a6utNr_2Ae1g"},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.neighbors import NearestNeighbors\n","import pandas as pd\n","import math\n","from sklearn.metrics import pairwise_distances\n","from scipy.spatial.distance import cityblock, hamming\n","from sklearn.preprocessing import normalize"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHaRYqCnykZz"},"source":["def check_numeric(X):\n","  newX = np.array(X).reshape(-1)\n","  return all(not isinstance(n, str) for n in newX)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n4lcmIQvsn6Q"},"source":["def error_return(p):\n","  ranked = np.arange(p, dtype=int) \n","  weight = np.empty((1,p))\n","  weight = np.squeeze(weight) \n","  weight[:] = np.nan\n","  return ranked, weight"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MDCPZoSWJzf9"},"source":["\n","### Preprocessing data and call feature selection algorithm"]},{"cell_type":"code","metadata":{"id":"FToEQpI3J5gK"},"source":["def I_Relief2_configure(X,Y, **kwargs):\n","  X = np.array(X)\n","  Y = np.array(Y)\n","  numOfIterations, categoricalX, kernelWidth, theta = kwargs['numOfIterations'], kwargs['categoricalX'], kwargs['kernelWidth'], kwargs['theta']\n","\n","  if not check_numeric(X):\n","    print('X does not contain numeric data')\n","    p = X.shape[1] # no of attributes\n","    return error_return(p) \n","\n","  # Check if the input sizes are consistent\n","  if Y.shape[0] != X.shape[0]:\n","    print('number of instances and output labels doesnot match')\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","  \n","  # converting classes as 0 to #classes\n","  [Y, grp] = pd.factorize(Y)\n","\n","  # grpToInd contains class to index mapping, grpToInd[className]= ind\n","  grpToInd={}\n","  for ind, g in enumerate(grp):\n","    grpToInd[g]= ind\n","\n","  # removing incomplete instances\n","  df_XY = pd.DataFrame(X)\n","  df_XY['Y'] = Y\n","  df_XY = df_XY.dropna()\n","\n","  X, Y = np.array(df_XY.iloc[:, 0:-1]), np.array(df_XY.iloc[:, -1])\n","  Ngrp = len(grp)\n","  N = X.shape[0]\n","  C = np.zeros((N,Ngrp))\n","  C[np.arange(N), Y] = True\n","\n","  \n","  # # Checking the number of classes\n","  # if Ngrp>2:\n","  #   print('Number of classes exceed 2')\n","  #   p = X.shape[1] # no of attributes\n","  #   return error_return(p)\n","\n","  #  Do we have enough observations?\n","  if len(Y)<2:\n","    print('not enough instances')\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","\n","  # Check number of iterations\n","  if (not check_numeric([numOfIterations]) or numOfIterations<=0):\n","    print('numOfIterations is invalid')\n","  else:\n","    numOfIterations = math.ceil(numOfIterations)\n","    \n","  # Check kernel width\n","  if (not check_numeric([kernelWidth]) or kernelWidth<=0):\n","    print('kernelWidth is invalid')\n","\n","  # Check stop criterion theta\n","  if (not check_numeric([theta]) or theta<=0):\n","    print('Stop criterion theta is invalid')  \n","\n","  # Check the type of categoricalX\n","  if not categoricalX or (categoricalX != 'on' and categoricalX != 'off'):\n","      print('categoricalX is invalid')\n","  categoricalX = (categoricalX == 'on')   \n","\n","  # Find max and min for every predictor\n","  p = X.shape[1] # no of attributes\n","  Xmax = X.max(0)\n","  Xmin = X.min(0) \n","  Xdiff = Xmax - Xmin\n","  Xmean = np.mean(X, axis=0) \n","\n","  # Exclude single-valued attributes\n","  isDiffValue = Xdiff >= 1e-9  # boolean array of size #attributes [1,0,0,0]\n","  if not any(isDiffValue):\n","    print(\"All attributes are single valued attributes.\")\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","  \n","  X = X[:, isDiffValue ] \n","  Xdiff = Xdiff[isDiffValue] \n","  Xmean = Xmean[isDiffValue] \n","  rejected = [ i for i in range(len(isDiffValue)) if not isDiffValue[i]]  # indices of the deleted attributes (values range from 1 to p)\n","  accepted = [ i for i in range(len(isDiffValue)) if isDiffValue[i]]  # indices of remaining attributes (values range from 1 to p)\n","\n","  # Scale and center the attributes\n","  if not categoricalX:\n","      X = (X - Xmean) / Xdiff \n","\n","  # Call I_Relief2. By default all weights are set to NaN.\n","  weight = np.empty(p) \n","  weight[:] = np.nan\n","\n","  weight[accepted] = I_Relief2(X, Y, C, numOfIterations, categoricalX, kernelWidth, theta) \n","\n","  # Assign ranks to attributes\n","  sorted = np.argsort(-weight[accepted])\n","  accepted = np.array(accepted)\n","  ranked = accepted[sorted]\n","  ranked = np.append(ranked, rejected)\n","  ranked = ranked.astype(int)\n","\n","  return ranked, weight\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6a1zuATsNfV1"},"source":["# I-Relief2 algorithm function"]},{"cell_type":"code","metadata":{"id":"1qwWjfJzAe2u"},"source":["def I_Relief2(scaledX, Y, C, numOfIterations, categoricalX, kernelWidth, theta):\n","  \n","  # I-Relief2 for classification\n","  numInstances,numAttr = scaledX.shape \n","  attrWeights = np.ones((numAttr,1))/numAttr \n","  # print(attrWeights)\n","  # C is boolean 2D matrix of size (N, Ngrp) i.e. (Number of instances vs Number of classes)\n","  numClasses = C.shape[1]   # Ngrp\n","\n","   # Make searcher objects, one object per class. \n","  instIdxPerClass = {}  \n","  for c in range(numClasses):\n","      c_C = C[:,c]\n","      instIdxPerClass[c] = np.array([i for i in range(len(c_C)) if c_C[i]], dtype=int)   # instances of class c\n","  \n","  # selecting distance function\n","  distFunc = cityblock\n","  distFunc2 = Cityblock\n","  if categoricalX:\n","    distFunc = hamming\n","    distFunc2 = Hamming\n","  else: \n","    distFunc = cityblock\n","    distFunc2 = Cityblock\n","  \n","   # Outer loop, for updating attribute weights iteratively\n","  for i in range(numOfIterations):\n","\n","    pairwiseWeightedDistances = np.array(pairwise_distances(scaledX, metric=distFunc, w=attrWeights))\n","    # print(\"pairwiseWeightedDistances : \", pairwiseWeightedDistances)\n","    pairwiseKernels = kernel_func(pairwiseWeightedDistances, kernelWidth)\n","    # print(\"pairwiseKernels : \", pairwiseKernels)\n","    pM = np.zeros((numInstances, numClasses, numInstances)) # probality of the i-th training example being nearest miss of the pattern x_n\n","    pH = np.zeros((numInstances, numInstances)) # probality of the i-th training example being nearest hit of the pattern x_n\n","    pO = np.zeros((numInstances, 1)) # probality of the i-th training example being outlier\n","\n","\n","    # calculating pM, pH, pO\n","    for j in range(numInstances):\n","      targetInstClass = Y[j]\n","      allMisses = np.array([], dtype=int)\n","\n","      for c in range(numClasses):\n","        if c == targetInstClass: \n","          hits = instIdxPerClass[c] # hit indices of class c with respect to jth target instance\n","          hits = hits[hits != j]\n","          hitKernels = pairwiseKernels[j, hits]\n","          pH[j, hits] = hitKernels/np.sum(hitKernels)\n","        else:\n","          misses = instIdxPerClass[c] # miss indices of class c with respect to jth target instance\n","          allMisses = np.append(allMisses, misses)\n","          missKernels = pairwiseKernels[j, misses]\n","          pM[j,c,misses] = missKernels/np.sum(missKernels)\n","\n","      allMissKernels = pairwiseKernels[j, allMisses]\n","      allKernels = pairwiseKernels[j, :]\n","      pO[j,0] = sum(allMissKernels)/(sum(allKernels) - pairwiseKernels[j,j]) # deleting kernel of targer in the denominator \n","\n","    # print('pO', pO)\n","    # print('pM', pM)\n","    # print('pH', pH)\n","\n","\n","    # calculating v\n","    v = np.zeros((numAttr,1))\n","\n","    for j in range(numInstances):\n","      targetInstClass = Y[j]\n","      targetInst = scaledX[j, :]\n","      m_bar = np.zeros((numAttr,1)) # shape: (numOfFeatures x 1)\n","      h_bar = np.zeros((numAttr,1)) # shape: (numOfFeatures x 1)\n","      m_bars = [] #list to hold all m_bar\n","\n","      for c in range(numClasses):\n","        if c == targetInstClass: \n","          hits = instIdxPerClass[c] # hit indices of class c with respect to jth target instance\n","          hits = hits[hits != j]\n","          hitInstances = scaledX[hits, :]\n","          h = np.transpose(distFunc2(targetInst, hitInstances)) # shape: (numOfFeatures x numOfHits)\n","          # print(\"H : \" , h) \n","          beta = pH[j, hits].reshape(-1,1) #shape: (numOfhits x 1) \n","          h_bar = np.matmul(h, beta) # shape: (numOfFeatures x 1)\n","        else:\n","          misses = instIdxPerClass[c] # miss indices of class c with respect to jth target instance\n","          missInstances = scaledX[misses, :]\n","          m = np.transpose(distFunc2(targetInst, missInstances)) # shape: (numOfFeatures x numOfMisses) \n","          # print(\"M : \", m)\n","          alpha = pM[j, c, misses].reshape(-1,1) #shape: (numOfMisses x 1)\n","          m_bar = np.matmul(m, alpha)            # shape: (numOfFeatures x 1)\n","          m_bars.append(m_bar)\n","\n","      # getting the min(m_bar-h_bar)\n","      length = np.Inf\n","      min_mbar = np.zeros((numAttr,1))\n","      for m_bar in m_bars:\n","        l = np.linalg.norm(m_bar)\n","        if l<length:\n","          length =l\n","          min_mbar = m_bar\n","          \n","      gamma = (1 - pO[j])\n","      v = v +  gamma * (min_mbar - h_bar)\n","    \n","    v = v/numInstances\n","    # print(\"v= \", v)\n","    v[v<0] = 0 # taking vPlus\n","    # print(\"v+= \", v)\n","    newWeights = normalize(v, norm='l2', axis=0)\n","    # print(\"newWeights= \", newWeights)\n","    weightDiff = newWeights - attrWeights\n","    _, weightDiffNorm = normalize(weightDiff, norm='l2', axis=0, return_norm=True)\n","    attrWeights = newWeights\n","\n","    if weightDiffNorm < theta:\n","      break\n","\n","  return np.squeeze(attrWeights)    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nV4ywAhqcWaF"},"source":["def kernel_func(d, kernelWidth):\n","  return np.exp(-d/kernelWidth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLkuPu0v2tRo"},"source":["def Cityblock(thisX, X):\n","  d = abs(X - thisX) \n","  return d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-2iwGin2tdA"},"source":["def Hamming(thisX, X):\n","  d = (X != thisX).astype(int) \n","  return d\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQgt2FhDQL5a"},"source":["# def permute(x):\n","#   if len(x) == 7:\n","#     global X\n","#     global Y\n","#     Y.append((x[0] ^ x[1] ^ x[2]))\n","#     X.append(x)\n","#     return\n","#   x = np.append(x,0)\n","#   permute(x)\n","#   x = x[0:-1]\n","#   x = np.append(x,1)\n","#   permute(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLcbYBwbXmAd"},"source":["# X = []\n","# Y = []\n","# x = np.array([], dtype=int)\n","# permute(x)\n","# X = np.array(X)\n","# Y = np.array(Y)\n","# ranked, weight= I_Relief2_configure(X, Y, numOfIterations=5, categoricalX = 'on', kernelWidth = 3, theta = 1e-9)\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6g9wkOs_fTTi"},"source":["# # test classification dataset\n","# from sklearn.datasets import make_classification\n","# # define dataset\n","# X, Y = make_classification(n_samples=400, n_features=10, n_informative=5, n_redundant=0,shuffle=False, random_state=1)\n","# # summarize the dataset\n","# # X = X.astype(int)\n","# # print(X, Y)\n","# ranked, weight= I_Relief2_configure(X, Y, numOfIterations=10, categoricalX = 'off', kernelWidth = 3, theta = 1e-9)\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)\n","# print('ranked weight')\n","# for r in ranked:\n","#   print(r,'th features weight= ',weight[r])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eE3bquUTKHkQ"},"source":[""],"execution_count":null,"outputs":[]}]}