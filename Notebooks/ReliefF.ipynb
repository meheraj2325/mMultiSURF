{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"ReliefF.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"a6utNr_2Ae1g","executionInfo":{"status":"ok","timestamp":1618309171856,"user_tz":-360,"elapsed":3712,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.neighbors import NearestNeighbors\n","import pandas as pd\n","import math\n","import time"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHaRYqCnykZz","executionInfo":{"status":"ok","timestamp":1618309171860,"user_tz":-360,"elapsed":3707,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["def check_numeric(X):\n","  newX = np.array(X).reshape(-1)\n","  return all(not isinstance(n, str) for n in newX)\n","\n","# X=np.array([[6,7,8],[3,0,5]])\n","# print(check_numeric(X))\n","# print(X)\n","# print(check_numeric([1,2,3]))"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"n4lcmIQvsn6Q","executionInfo":{"status":"ok","timestamp":1618309171861,"user_tz":-360,"elapsed":3704,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["def error_return(p):\n","  ranked = np.arange(p, dtype=int) \n","  weight = np.empty((1,p))\n","  weight = np.squeeze(weight) \n","  weight[:] = np.nan\n","  return ranked, weight"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MDCPZoSWJzf9"},"source":["\n","### Preprocessing data and call feature selection algorithm"]},{"cell_type":"code","metadata":{"id":"FToEQpI3J5gK","executionInfo":{"status":"ok","timestamp":1618309171861,"user_tz":-360,"elapsed":3702,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["def ReliefF_configure(X,Y,K, **kwargs):\n","  X = np.array(X)\n","  Y = np.array(Y)\n","  prior, numUpdates, categoricalX = kwargs['prior'], kwargs['numUpdates'], kwargs['categoricalX']\n","\n","  # if not check_numeric(X):\n","  #   print('X does not contain numeric data')\n","  #   p = X.shape[1] # no of attributes\n","  #   return error_return(p) \n","\n","  # Check if the input sizes are consistent\n","  if Y.shape[0] != X.shape[0]:\n","    print('number of instances and output labels doesnot match')\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","  \n","  # converting classes as 0 to #classes\n","  [Y, grp] = pd.factorize(Y)\n","\n","  # grpToInd contains class to index mapping, grpToInd[className]= ind\n","  grpToInd={}\n","  for ind, g in enumerate(grp):\n","    grpToInd[g]= ind\n","\n","  # removing incomplete instances\n","  # df_XY = pd.DataFrame(X)\n","  # df_XY['Y'] = Y\n","  # df_XY = df_XY.dropna()\n","  # X, Y = np.array(df_XY.iloc[:, 0:-1]), np.array(df_XY.iloc[:, -1])\n","  \n","  Ngrp = len(grp)\n","  N = X.shape[0]\n","  C = np.zeros((N,Ngrp))\n","  C[np.arange(N), Y] = True\n","  \n","  # Get class probs\n","  if not prior or prior == 'empirical':\n","    classProb = C.sum(0)\n","  elif prior == 'uniform':\n","    classProb = np.ones((1, Ngrp))\n","  elif isinstance(prior, dict):\n","    classProb = np.zeros((1,Ngrp))\n","    # if prior is a dictionary of class and prior prob\n","    if not len(prior):\n","      print('prior dictionrary is empty')\n","      p = X.shape[1] # no of attributes\n","      return error_return(p)\n","    for g, prob in prior.items():\n","      classProb[grpToInd[g]]=prob\n","  elif check_numeric(prior):\n","    if len(prior)!= Ngrp or any(p <0 for p in prior) or not all(isinstance(p, float) for p in prior) or all(p == 0 for p in prior) :\n","      print('prior doesnot fulfil all conditions')\n","      p = X.shape[1] # no of attributes\n","      return error_return(p)\n","    classProb = prior\n","  else:\n","    print('prior is invalid')\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","  \n","  #  Normalize class probs\n","  classProb = classProb/classProb.sum()\n","  classProb = np.squeeze(classProb) \n","  #  If there are classes with zero probs, remove them\n","  zeroProb = classProb != 0\n","  \n","  t = [not classProb[y]==0 for y in Y] # contains array of size [Ngrp,1] with values [True, True, False ...]\n","  X = X[t]\n","  Y = Y[t]\n","  C = C[t]\n","  C = C[:,zeroProb]\n","  classProb = classProb[zeroProb]\n","\n","  #  Do we have enough observations?\n","  if len(Y)<2:\n","    print('not enough instances')\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","\n","  if not check_numeric([K]) or K<0:\n","    print('invalid value of K')\n","    p = X.shape[1] # no of attributes\n","    return error_return(property)\n","  K= math.ceil(K)\n","\n","  # Check number of updates\n","  if (not numUpdates=='all') and (not check_numeric([numUpdates]) or numUpdates<=0):\n","    print('numUpdates is invalid')\n","  elif (not numUpdates) or numUpdates=='all':\n","    numUpdates = X.shape[0]\n","  else:\n","    numUpdates = math.ceil(numUpdates)\n","    \n","  # Check the type of categoricalX\n","  if not categoricalX or (categoricalX != 'on' and categoricalX != 'off'):\n","      print('categoricalX is invalid')\n","  categoricalX = (categoricalX == 'on')   \n","\n","  # Find max and min for every predictor\n","  p = X.shape[1] # no of attributes\n","  Xmax = X.max(0)\n","  Xmin = X.min(0) \n","  Xdiff = Xmax - Xmin\n","  Xmean = np.mean(X, axis=0) \n","\n","  # Exclude single-valued attributes\n","  isDiffValue = Xdiff >= 1e-9  # boolean array of size #attributes [1,0,0,0]\n","  if not any(isDiffValue):\n","    p = X.shape[1] # no of attributes\n","    return error_return(p)\n","  \n","  X = X[:, isDiffValue] \n","  Xmax = Xmax[isDiffValue] \n","  Xmin = Xmin[isDiffValue] \n","  Xdiff = Xdiff[isDiffValue] \n","  Xmean = Xmean[isDiffValue]\n","\n","  rejected = [ i for i in range(len(isDiffValue)) if not isDiffValue[i]]  # indices of the deleted attributes (values range from 1 to p)\n","  accepted = [ i for i in range(len(isDiffValue)) if isDiffValue[i]]  # indices of remaining attributes (values range from 1 to p)\n","\n","  # Scale and center the attributes\n","  if not categoricalX:\n","    X = (X - Xmin) / Xdiff \n","\n","  # The #updates cannot be more than the #observations\n","  numUpdates = min(numUpdates, X.shape[0])\n","\n","  # Call ReliefF. By default all weights are set to NaN.\n","  weight = np.empty(p) \n","  weight[:] = np.nan\n","\n","  weight[accepted] = ReliefF(X,C,classProb,numUpdates,K,categoricalX) \n","\n","  # Assign ranks to attributes\n","  sorted = np.argsort(-weight[accepted])\n","  accepted = np.array(accepted)\n","  ranked = accepted[sorted]\n","  ranked = np.append(ranked, rejected)\n","  ranked = ranked.astype(int)\n","\n","  return ranked, weight \n","\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6a1zuATsNfV1"},"source":["# ReliefF algorithm function"]},{"cell_type":"code","metadata":{"id":"1qwWjfJzAe2u","executionInfo":{"status":"ok","timestamp":1618309171862,"user_tz":-360,"elapsed":3701,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["def ReliefF(scaledX,C,classProb,numUpdates,K,categoricalX):\n","  \n","  # ReliefF for classification\n","  numInstances,numAttr = scaledX.shape \n","  attrWeights = np.zeros(numAttr) \n","  # C is boolean 2D matrix of size (N, Ngrp) i.e. (Number of instances vs Number of classes)\n","  numClasses = C.shape[1]   # Ngrp\n","\n","  # Choose the random instances\n","  np.random.seed(123)\n","  rndIdx = np.random.choice(numInstances, numUpdates, replace=False)   # random indices of m instances from total of n instances\n","  idxVec = np.arange(numInstances)   # [0 .. N-1]\n","\n","   # Make searcher objects, one object per class. \n","  instIdxPerClass = {}  \n","  for c in range(numClasses):\n","      c_C = C[:,c]\n","      instIdxPerClass[c] = np.array([i for i in range(len(c_C)) if c_C[i]], dtype=int)   # instances of class c\n","  \n","  # selecting distance function\n","  distFunc = 'manhattan'\n","  if categoricalX:\n","    distFunc = 'hamming'\n","  else: \n","    distFunc = 'manhattan'\n","  \n","   # Outer loop, for updating attribute weights iteratively\n","  for i in range(numUpdates):\n","    targetIdx = rndIdx[i]\n","    \n","      # Choose the correct random observation\n","    targetInst = scaledX[targetIdx,:]\n","\n","      # Find the class for this observation\n","    targetC = C[targetIdx, :]\n","    thisC = np.array([i for i in range(len(targetC)) if targetC[i]]).item() # taking the class of target instance\n","    \n","      # Find the k-nearest hits \n","    sameClassIdx = instIdxPerClass[thisC] \n","    \n","      # we may not always find numNeighbor Hits\n","    lenHits = min(len(sameClassIdx)-1,K) \n","\n","      # find nearest hits\n","      # It is not guaranteed that the first hit is the same as targetIdx. Since\n","      # they have the same class, it does not matter. If we add observation\n","      # weights in the future, we will need here something similar to what we\n","      # do in ReliefReg.\n","    # print('HitFit : ', scaledX[sameClassIdx])\n","    Hits = [] \n","    if lenHits>0:\n","        nearestNeighborHits = NearestNeighbors(n_neighbors=lenHits+1, algorithm='auto', metric= distFunc).fit(scaledX[sameClassIdx])\n","        idxH = nearestNeighborHits.kneighbors([targetInst], lenHits+1, return_distance=False)\n","        idxH = np.squeeze(idxH)\n","        Hits = sameClassIdx[idxH[1:]] \n","\n","      # Process misses\n","    missClass = [i for i in range(len(targetC)) if not targetC[i]]\n","    Misses = [] \n","    \n","    if len(missClass):  # Make sure there are misses!\n","      # Find the k-nearest misses Misses(C,:) for each class C ~= class(targetInst)\n","      # Misses will be of size (no. of classes -1)x(K)\n","      Misses = np.empty((numClasses-1, min(numInstances,K+1)), dtype= int)   # last column has class index\n","      Misses[:] = -1\n","\n","      for mi in range(len(missClass)):\n","          \n","            # find all observations of this miss class\n","          missClassIdx = instIdxPerClass[missClass[mi]]\n","          \n","            # we may not always find K misses\n","          lenMiss = min(len(missClassIdx),K) \n","          \n","          # print('Missfit :', scaledX[missClassIdx])\n","\n","            # find nearest misses\n","          if lenMiss>0:\n","            nearestNeighborMiss = NearestNeighbors(n_neighbors=lenMiss, algorithm='auto', metric= distFunc).fit(scaledX[missClassIdx])\n","            idxM = nearestNeighborMiss.kneighbors([targetInst], lenMiss, return_distance=False)\n","            idxM = np.squeeze(idxM)\n","            Misses[mi, 0:lenMiss] = missClassIdx[idxM]\n","      \n","        # Misses contains obs indices for miss classes, sorted by dist.\n","      Misses[:,-1] = missClass \n","            \n","      #***************** ATTRIBUTE UPDATE *****************************\n","      # Inner loop to update weights for each attribute:\n","\n","    # print('targetID :',targetIdx)\n","    # print(\"target :\",targetInst)\n","    # print('HitId :', Hits)\n","    # print(\"Hit :\", X[Hits])\n","    # print('MissId :', Misses[:, 0:-1])\n","    # print(\"Miss :\", X[Misses[:, 0:-1]])\n","    \n","    for j in range(numAttr):\n","        dH = diffH(j,scaledX,targetIdx,Hits, categoricalX)/numUpdates\n","        # print('dH', dH) \n","        dM = diffM(j,scaledX,targetIdx,Misses,categoricalX ,classProb)/numUpdates\n","        # print('dM', dM)\n","        attrWeights[j] = attrWeights[j] - dH + dM \n","        attrWeights[j] = attrWeights[j]\n","\n","      \n","      #****************************************************************\n","    \n","    # print('attrWeights : ', attrWeights)\n","  \n","  return attrWeights    "],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLkuPu0v2tRo","executionInfo":{"status":"ok","timestamp":1618309171862,"user_tz":-360,"elapsed":3700,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["def cityblock(thisX, X):\n","  d = abs(X - thisX) \n","  return d"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-2iwGin2tdA","executionInfo":{"status":"ok","timestamp":1618309171863,"user_tz":-360,"elapsed":3699,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["def hamming(thisX, X):\n","  d = (X != thisX).astype(int) \n","  return d\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"w40aIoG-Ae28","executionInfo":{"status":"ok","timestamp":1618309171863,"user_tz":-360,"elapsed":3698,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["#--------------------------------------------------------------------------\n","# DIFFH (for RelieffClass): Function to calculate difference measure\n","# for an attribute between the selected instance and its hits\n","\n","def diffH(a, X, targetIdx, Hits, categoricalX):\n","\n","  # print(a, targetIdx, Hits, categoricalX)\n","\n","  distMeas = 0 \n","\n","  # If no hits, return zero by default\n","  if not len(Hits):\n","      return distMeas\n","\n","  # Calculate weighted sum of distances\n","  if categoricalX:\n","    distMeas = np.sum(hamming(X[targetIdx, a], X[Hits, a]))\n","  else:\n","    distMeas = np.sum(cityblock(X[targetIdx, a], X[Hits,a]))\n","\n","  # print('For attribute ',a,' Hit distmeas : ', distMeas/len(Hits))\n","\n","  return distMeas/len(Hits)\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Rb0WZu42j7T","executionInfo":{"status":"ok","timestamp":1618309171863,"user_tz":-360,"elapsed":3696,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["#--------------------------------------------------------------------------\n","# DIFFM (for RelieffClass) : Function to calculate difference measure\n","# for an attribute between the selected instance and its misses\n","def diffM(a, X, targetIdx, Misses, categoricalX, classProb):\n","  distMeas = 0 \n","  MissWithoutC = Misses[:, 0:-1]\n","  # If no misses, return zero\n","  if not len(Misses):\n","    return distMeas\n","\n","  # Loop over misses\n","  for mi in range(Misses.shape[0]):\n","    ismiss = (Misses[mi, 0:-1] != -1) \n","    \n","    if any(ismiss):\n","        cls = Misses[mi,-1] \n","        nmiss = np.sum(ismiss)           \n","\n","        if categoricalX:\n","          distMeas = distMeas + (np.sum(hamming(X[targetIdx, a], X[MissWithoutC[mi, ismiss], a]))/nmiss) * classProb[cls]\n","        else:\n","          distMeas = distMeas + (np.sum(cityblock(X[targetIdx, a], X[MissWithoutC[mi,ismiss], a]))/nmiss) * classProb[cls]\n","\n","  # Normalize class probabilities.\n","  # This is equivalent to P(C)/(1-P(class(R))) in ReliefF paper.\n","  totProb = np.sum(classProb[Misses[:,-1]]) \n","  distMeas = distMeas/totProb \n","\n","  # print('For attribute ',a,' Miss distmeas : ', distMeas)\n","\n","  return distMeas\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"24fjwbzxuzBa","executionInfo":{"status":"ok","timestamp":1618309171864,"user_tz":-360,"elapsed":3695,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["# X = np.array([[0,0,0,0,1,0,0],\n","#               [0,1,0,1,0,1,0],\n","#               [1,0,0,0,1,1,0],\n","#               [0,0,0,1,0,0,0],\n","#               [1,1,0,0,0,0,0],\n","#               [0,1,0,0,1,0,0],\n","#               [0,0,0,0,0,1,0],\n","#               [1,0,0,1,0,0,0],\n","#               [1,0,1,0,0,0,1],\n","#               [1,1,0,0,1,0,1],\n","#               [0,0,0,0,0,0,1],\n","#               [1,0,1,1,1,1,1],\n","#               [1,0,0,0,0,0,0],\n","#               [1,0,0,1,0,1,1],\n","#               [0,1,1,0,0,0,0],\n","#               [0,0,1,1,0,0,1],\n","#               [1,1,0,1,0,0,0],\n","#               [1,0,1,0,1,0,1],\n","#               [0,1,1,1,0,0,1],\n","#               [1,1,1,1,1,1,1]])\n","\n","# Y = np.array([0,1,1,0,0,1,0,1,1,0,0,1,1,1,1,0,0,1,1,0])\n","\n","# ReliefF_configure(X,Y,K=3,prior='uniform', numUpdates='all', categoricalX='on')\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQe2rjPuiyP5","executionInfo":{"status":"ok","timestamp":1618309171864,"user_tz":-360,"elapsed":3694,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["# X = np.array([[1,0,1],\n","#               [1,0,0],\n","#               [0,1,1],\n","#               [0,1,0],\n","#               [0,0,1],\n","#               [0,0,0],\n","#               [1,1,1],\n","#               [1,1,0]])\n","\n","# Y = np.array([1,1,1,1,0,0,0,0])\n","# ranked, weight= ReliefF_configure(X,Y,K=1,prior='uniform', numUpdates='all', categoricalX='on')\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQgt2FhDQL5a","executionInfo":{"status":"ok","timestamp":1618309171865,"user_tz":-360,"elapsed":3693,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["# def permute(x):\n","#   if len(x) == 7:\n","#     global X\n","#     global Y\n","#     Y.append((x[0] ^ x[1]))\n","#     X.append(x)\n","#     return\n","#   x = np.append(x,0)\n","#   permute(x)\n","#   x = x[0:-1]\n","#   x = np.append(x,1)\n","#   permute(x)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLcbYBwbXmAd","executionInfo":{"status":"ok","timestamp":1618309171865,"user_tz":-360,"elapsed":3692,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["# X = []\n","# Y = []\n","# x = np.array([], dtype=int)\n","# permute(x)\n","# X = np.array(X)\n","# Y = np.array(Y)\n","# ranked, weight=ReliefF_configure(X,Y,K=10,prior='uniform', numUpdates=len(Y)/2, categoricalX='on')\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"6g9wkOs_fTTi","executionInfo":{"status":"ok","timestamp":1618309171865,"user_tz":-360,"elapsed":3690,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["# # test classification dataset\n","# from sklearn.datasets import make_classification\n","# # define dataset\n","# X, Y = make_classification(n_samples=100, n_features=15, n_informative=5, n_redundant=0,shuffle=False, random_state=1)\n","# # summarize the dataset\n","# print(X.shape, Y.shape)\n","# ranked, weight= ReliefF_configure(X,Y,K=10,prior='empirical', numUpdates='all', categoricalX='off')\n","\n","# print('ranked')\n","# print(ranked)\n","# print('weight')\n","# print(weight)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"aOX0asWFteMH","executionInfo":{"status":"ok","timestamp":1618309171866,"user_tz":-360,"elapsed":3690,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["# from sklearn.datasets import load_iris, load_digits, load_wine\n","# X, Y = load_iris(return_X_y= True)\n","# print('dataset: iris')\n","# ranked, weight = ReliefF_configure(X,Y,K=10,prior='empirical', numUpdates='all', categoricalX='off')\n","# print(ranked, weight)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"5RAENFDwfD8T","executionInfo":{"status":"ok","timestamp":1618309171866,"user_tz":-360,"elapsed":3688,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}}},"source":["# from sklearn.datasets import load_iris, load_digits, load_wine\n","# X, Y = load_wine(return_X_y= True)\n","# print(X.shape[1])\n","# print('dataset: wine')\n","# ranked, weight = ReliefF_configure(X,Y,K=10,prior='empirical', numUpdates='all', categoricalX='off')\n","# print(ranked, weight)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9Mva5BHshY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618309593255,"user_tz":-360,"elapsed":920,"user":{"displayName":"Rahat Rizvi Rahman","photoUrl":"","userId":"16342705232884272841"}},"outputId":"17611f36-c76e-47bb-af4e-9ef86ef9a1b1"},"source":["# X= np.array([[0,0],[1,2],[2,4],[3,6],[4,8],[6,5],[7,7],[8,10],[9,12],[10,13]])\n","X= np.array([[0,0],[1,2],[2,4],[3,6],[4,8],[6,5],[7,7],[8,9],[9,10],[10,11]])\n","Y= np.array([1,1,1,1,1,2,2,2,2,2])\n","ranked, weight = ReliefF_configure(X,Y,K=10,prior='empirical', numUpdates='all', categoricalX='off')\n","print(ranked, weight)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["[0 1] [0.4        0.11818182]\n"],"name":"stdout"}]}]}